# ğŸ“š REFERENCIAS BIBLIOGRÃFICAS - VISION
## Sistema de DetecciÃ³n de Somnolencia en Conductores

---

## ğŸ“– ÃNDICE

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Papers CientÃ­ficos Fundamentales](#papers-cientÃ­ficos-fundamentales)
3. [Estudios de DetecciÃ³n de Somnolencia](#estudios-de-detecciÃ³n-de-somnolencia)
4. [Reconocimiento Facial e IA](#reconocimiento-facial-e-ia)
5. [Frameworks y LibrerÃ­as](#frameworks-y-librerÃ­as)
6. [Datasets de Entrenamiento](#datasets-de-entrenamiento)
7. [Normativas y EstÃ¡ndares](#normativas-y-estÃ¡ndares)
8. [Citas en el Proyecto](#citas-en-el-proyecto)

---

## 1. INTRODUCCIÃ“N

Este documento recopila todas las referencias bibliogrÃ¡ficas, papers cientÃ­ficos, estudios y recursos tÃ©cnicos que fundamentan el desarrollo del sistema VISION (Sistema de DetecciÃ³n de Somnolencia en Conductores). La documentaciÃ³n sigue el formato de citaciÃ³n **APA 7Âª ediciÃ³n** y **IEEE** para referencias tÃ©cnicas.

---

## 2. PAPERS CIENTÃFICOS FUNDAMENTALES

### 2.1 Eye Aspect Ratio (EAR)

**[1] SoukupovÃ¡, T., & ÄŒech, J. (2016).** *Real-Time Eye Blink Detection using Facial Landmarks.* 21st Computer Vision Winter Workshop, Rimske Toplice, Slovenia.

```
ABSTRACT:
Este paper introduce el mÃ©todo Eye Aspect Ratio (EAR) para detectar parpadeos
en tiempo real utilizando landmarks faciales. El mÃ©todo calcula la relaciÃ³n entre
las distancias verticales y horizontales de los puntos del ojo, permitiendo
identificar cuÃ¡ndo los ojos estÃ¡n cerrados sin necesidad de clasificadores
complejos.

RELEVANCIA PARA VISION:
- Base matemÃ¡tica del algoritmo EAR implementado
- FÃ³rmula: EAR = (||p2-p6|| + ||p3-p5||) / (2 * ||p1-p4||)
- Umbral tÃ­pico: EAR < 0.3 indica ojos cerrados
- Usado para detectar somnolencia en tiempo real

CITACIÃ“N IEEE:
T. SoukupovÃ¡ and J. ÄŒech, "Real-Time Eye Blink Detection using Facial
Landmarks," in Proc. 21st Computer Vision Winter Workshop, Rimske Toplice,
Slovenia, 2016.
```

**URL:** http://vision.fe.uni-lj.si/cvww2016/proceedings/papers/05.pdf

---

### 2.2 Deep Residual Learning (ResNet)

**[2] He, K., Zhang, X., Ren, S., & Sun, J. (2016).** *Deep Residual Learning for Image Recognition.* IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778.

```
ABSTRACT:
Introduce las Redes Neuronales Residuales (ResNet) que permiten entrenar
redes extremadamente profundas (hasta 152 capas) mediante conexiones residuales
(skip connections). ResNet-34 es la base de FaceRecognitionNet.

RELEVANCIA PARA VISION:
- Arquitectura base de FaceRecognitionNet
- 34 capas con residual blocks
- Permite embeddings faciales de 128 dimensiones
- Pre-entrenado en ImageNet (1.28M imÃ¡genes)

CITACIÃ“N IEEE:
K. He, X. Zhang, S. Ren, and J. Sun, "Deep Residual Learning for Image
Recognition," in Proc. IEEE Conf. Computer Vision and Pattern Recognition
(CVPR), 2016, pp. 770-778.

DOI: 10.1109/CVPR.2016.90
```

**URL:** https://arxiv.org/abs/1512.03385

---

### 2.3 FaceNet: Face Recognition

**[3] Schroff, F., Kalenichenko, D., & Philbin, J. (2015).** *FaceNet: A Unified Embedding for Face Recognition and Clustering.* IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 815-823.

```
ABSTRACT:
Propone un sistema de reconocimiento facial que aprende directamente un mapeo
de imÃ¡genes faciales a un espacio euclidiano compacto donde las distancias
corresponden directamente a la similitud facial. Utiliza triplet loss para
el entrenamiento.

RELEVANCIA PARA VISION:
- Base teÃ³rica para face embeddings de 128D
- MÃ©trica de distancia euclidiana para comparaciÃ³n
- Threshold: distancia < 0.6 = misma persona
- Usado potencialmente para identificaciÃ³n de conductores

CITACIÃ“N IEEE:
F. Schroff, D. Kalenichenko, and J. Philbin, "FaceNet: A Unified Embedding
for Face Recognition and Clustering," in Proc. IEEE Conf. Computer Vision
and Pattern Recognition (CVPR), 2015, pp. 815-823.

DOI: 10.1109/CVPR.2015.7298682
```

**URL:** https://arxiv.org/abs/1503.03832

---

### 2.4 300 Faces In-The-Wild Challenge (300-W)

**[4] Sagonas, C., Antonakos, E., Tzimiropoulos, G., Zafeiriou, S., & Pantic, M. (2016).** *300 Faces In-The-Wild Challenge: Database and Results.* Image and Vision Computing, 47, 3-18.

```
ABSTRACT:
Introduce el dataset 300-W para detecciÃ³n de landmarks faciales con 68 puntos
de referencia. Incluye imÃ¡genes en condiciones no controladas ("in-the-wild")
con variaciones en iluminaciÃ³n, pose y oclusiones.

RELEVANCIA PARA VISION:
- Dataset usado para entrenar FaceLandmark68Net
- EstÃ¡ndar de 68 landmarks faciales (iBUG)
- Puntos 36-41: ojo izquierdo (usado en VISION)
- Puntos 42-47: ojo derecho (usado en VISION)
- Puntos 48-67: boca (usado en VISION)

CITACIÃ“N APA:
Sagonas, C., Antonakos, E., Tzimiropoulos, G., Zafeiriou, S., & Pantic, M.
(2016). 300 Faces In-The-Wild Challenge: Database and Results. Image and
Vision Computing, 47, 3-18.

DOI: 10.1016/j.imavis.2016.01.002
```

**URL:** https://ibug.doc.ic.ac.uk/resources/300-W/

---

### 2.5 MobileNets: Efficient CNNs

**[5] Howard, A. G., et al. (2017).** *MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications.* arXiv preprint arXiv:1704.04861.

```
ABSTRACT:
Introduce arquitecturas CNN eficientes basadas en convoluciones separables
en profundidad (depthwise separable convolutions) optimizadas para dispositivos
mÃ³viles y embebidos.

RELEVANCIA PARA VISION:
- Base de TinyFaceDetector
- Depthwise separable convolutions (menos parÃ¡metros)
- Trade-off entre latencia y precisiÃ³n
- Permite detecciÃ³n en tiempo real en navegadores

CITACIÃ“N IEEE:
A. G. Howard et al., "MobileNets: Efficient Convolutional Neural Networks
for Mobile Vision Applications," arXiv:1704.04861, 2017.
```

**URL:** https://arxiv.org/abs/1704.04861

---

## 3. ESTUDIOS DE DETECCIÃ“N DE SOMNOLENCIA

### 3.1 Sistemas de DetecciÃ³n: RevisiÃ³n Completa

**[6] RamÃ­rez-Moreno, M. A., et al. (2019).** *Sistemas de detecciÃ³n de somnolencia en conductores: inicio, desarrollo y futuro.* I+D Revista de Investigaciones, 13(1), 91-105.

```
RESUMEN:
RevisiÃ³n exhaustiva de tÃ©cnicas para detectar somnolencia en conductores,
incluyendo mÃ©todos basados en visiÃ³n por computadora, anÃ¡lisis de seÃ±ales
fisiolÃ³gicas (EEG, ECG), y patrones de conducciÃ³n del vehÃ­culo. Analiza
ventajas y limitaciones de cada enfoque.

RELEVANCIA PARA VISION:
- Estado del arte en detecciÃ³n de somnolencia
- ComparaciÃ³n de mÃ©todos: visiÃ³n vs fisiolÃ³gicos vs vehÃ­culo
- JustificaciÃ³n del enfoque de visiÃ³n por computadora
- Tendencias futuras en el campo

CITACIÃ“N APA:
RamÃ­rez-Moreno, M. A., MejÃ­a-Henao, S., Pulgarin-Arias, M., & Betancur-
Monsalve, Y. (2019). Sistemas de detecciÃ³n de somnolencia en conductores:
inicio, desarrollo y futuro. I+D Revista de Investigaciones, 13(1), 91-105.

DOI: 10.33304/revinv.v13n1-2019008
```

**URL:** https://journalusco.edu.co/index.php/iregion/article/view/717

---

### 3.2 DetecciÃ³n en Dispositivos MÃ³viles

**[7] Flores, M. J., Armingol, J. M., & de la Escalera, A. (2023).** *DetecciÃ³n de somnolencia y distracciÃ³n en conductores y su implementaciÃ³n en dispositivos mÃ³viles: una revisiÃ³n.* InformaciÃ³n TecnolÃ³gica, 34(4), 1-12.

```
RESUMEN:
Propone un sistema portÃ¡til basado en visiÃ³n por computadora para detectar
somnolencia y distracciÃ³n en conductores, optimizado para operar en tiempo
real en dispositivos mÃ³viles (smartphones y tablets). EvalÃºa rendimiento
en hardware limitado.

RELEVANCIA PARA VISION:
- OptimizaciÃ³n para hardware limitado (similar a navegadores)
- TÃ©cnicas de reducciÃ³n de latencia
- Balance entre precisiÃ³n y velocidad
- ImplementaciÃ³n en JavaScript/navegadores

CITACIÃ“N APA:
Flores, M. J., Armingol, J. M., & de la Escalera, A. (2023). DetecciÃ³n de
somnolencia y distracciÃ³n en conductores y su implementaciÃ³n en dispositivos
mÃ³viles: una revisiÃ³n. InformaciÃ³n TecnolÃ³gica, 34(4), 1-12.

DOI: 10.4067/S0718-07642023000400001
```

**URL:** https://www.scielo.cl/scielo.php?pid=S0718-07642023000400001&script=sci_arttext

---

### 3.3 CaracterÃ­sticas Visuales Robustas

**[8] JimÃ©nez-Pinto, J., & Torres-Torriti, M. (2016).** *Sistema AutomÃ¡tico Para la DetecciÃ³n de DistracciÃ³n y Somnolencia en Conductores por Medio de CaracterÃ­sticas Visuales Robustas.* Revista Iberoamericana de AutomÃ¡tica e InformÃ¡tica Industrial RIAI, 13(4), 431-441.

```
RESUMEN:
Presenta un sistema automÃ¡tico que utiliza caracterÃ­sticas visuales robustas
(SURF, HOG) para detectar distracciÃ³n y somnolencia. Enfatiza la robustez
ante variaciones de iluminaciÃ³n y movimiento del vehÃ­culo.

RELEVANCIA PARA VISION:
- CaracterÃ­sticas visuales robustas para detecciÃ³n
- Manejo de condiciones de iluminaciÃ³n variable
- ValidaciÃ³n en condiciones reales de conducciÃ³n
- MÃ©tricas de evaluaciÃ³n de sistemas

CITACIÃ“N APA:
JimÃ©nez-Pinto, J., & Torres-Torriti, M. (2016). Sistema AutomÃ¡tico Para la
DetecciÃ³n de DistracciÃ³n y Somnolencia en Conductores por Medio de
CaracterÃ­sticas Visuales Robustas. Revista Iberoamericana de AutomÃ¡tica e
InformÃ¡tica Industrial RIAI, 13(4), 431-441.

DOI: 10.1016/j.riai.2016.09.001
```

**URL:** https://polipapers.upv.es/index.php/RIAI/article/view/9213

---

### 3.4 Estado FisiolÃ³gico de los Ojos

**[9] Espinoza, C., et al. (2019).** *DetecciÃ³n del estado fisiolÃ³gico de los ojos en Conductores mediante tÃ©cnicas de visiÃ³n artificial.* Ingeniare. Revista Chilena de IngenierÃ­a, 27(4), 564-576.

```
RESUMEN:
Aborda especÃ­ficamente la detecciÃ³n del estado fisiolÃ³gico de los ojos
(abiertos, cerrados, parpadeando) utilizando tÃ©cnicas de visiÃ³n artificial.
Propone mÃ©tricas basadas en la forma y apertura ocular.

RELEVANCIA PARA VISION:
- Fundamentos del anÃ¡lisis del estado de los ojos
- MÃ©tricas para cuantificar apertura ocular
- ValidaciÃ³n de algoritmos de detecciÃ³n de ojos
- ComparaciÃ³n con EAR

CITACIÃ“N APA:
Espinoza, C., Guevara, D., GuzmÃ¡n, E., & Trujillo, F. (2019). DetecciÃ³n del
estado fisiolÃ³gico de los ojos en Conductores mediante tÃ©cnicas de visiÃ³n
artificial. Ingeniare. Revista Chilena de IngenierÃ­a, 27(4), 564-576.

DOI: 10.4067/S0718-33052019000400564
```

**URL:** https://www.scielo.cl/scielo.php?pid=S0718-33052019000400564&script=sci_arttext

---

### 3.5 RevisiÃ³n SistemÃ¡tica de Fatiga

**[10] GarcÃ­a-LÃ³pez, R., & MartÃ­nez-SÃ¡nchez, J. (2024).** *Sistema inteligente para la detecciÃ³n de la fatiga: una revisiÃ³n sistemÃ¡tica.* Scribd Document 855892241.

```
RESUMEN:
RevisiÃ³n sistemÃ¡tica de los avances en sistemas inteligentes para la detecciÃ³n
de fatiga en conductores, enfocÃ¡ndose en tecnologÃ­as emergentes: visiÃ³n por
computadora, aprendizaje automÃ¡tico, redes neuronales profundas y sensores
multimodales.

RELEVANCIA PARA VISION:
- Estado del arte en sistemas inteligentes
- ComparaciÃ³n de tecnologÃ­as emergentes
- Deep Learning para detecciÃ³n de fatiga
- Futuras direcciones de investigaciÃ³n

CITACIÃ“N:
GarcÃ­a-LÃ³pez, R., & MartÃ­nez-SÃ¡nchez, J. (2024). Sistema inteligente para
la detecciÃ³n de la fatiga: una revisiÃ³n sistemÃ¡tica. Scribd.
```

**URL:** https://es.scribd.com/document/855892241/

---

## 4. RECONOCIMIENTO FACIAL E IA

### 4.1 IdentificaciÃ³n de Emociones

**[11] VÃ¡squez-Coronado, M., et al. (2022).** *Sistema de identificaciÃ³n de emociones a travÃ©s de reconocimiento facial utilizando inteligencia artificial.* Revista de IniciaciÃ³n CientÃ­fica, 8(1), 1-12.

```
RESUMEN:
Presenta un sistema de identificaciÃ³n de emociones utilizando reconocimiento
facial e IA. Emplea CNNs para clasificar expresiones faciales en 7 categorÃ­as
bÃ¡sicas. Relevante para entender la detecciÃ³n de gestos faciales.

RELEVANCIA PARA VISION:
- TÃ©cnicas de procesamiento de imÃ¡genes faciales
- ClasificaciÃ³n de expresiones faciales
- CNNs aplicadas a anÃ¡lisis facial
- Transfer learning en modelos faciales

CITACIÃ“N APA:
VÃ¡squez-Coronado, M., Mora-Mora, H., & Molina-Molina, S. (2022). Sistema
de identificaciÃ³n de emociones a travÃ©s de reconocimiento facial utilizando
inteligencia artificial. Revista de IniciaciÃ³n CientÃ­fica, 8(1), 1-12.
```

**URL:** https://www.redalyc.org/journal/6738/673870841013/html/

---

### 4.2 Control de Accesos con IA

**[12] MartÃ­nez-PÃ©rez, D., et al. (2022).** *Sistema de reconocimiento facial para el control de accesos mediante Inteligencia Artificial.* Revista de IniciaciÃ³n CientÃ­fica, 8(2), 1-10.

```
RESUMEN:
ImplementaciÃ³n de un sistema de control de accesos basado en reconocimiento
facial utilizando deep learning. Aborda aspectos prÃ¡cticos como iluminaciÃ³n,
Ã¡ngulos de captura y optimizaciÃ³n del modelo.

RELEVANCIA PARA VISION:
- ImplementaciÃ³n prÃ¡ctica de sistemas de reconocimiento
- OptimizaciÃ³n de modelos para tiempo real
- Manejo de condiciones variables
- Arquitecturas CNN eficientes

CITACIÃ“N APA:
MartÃ­nez-PÃ©rez, D., RodrÃ­guez-SÃ¡nchez, A., & LÃ³pez-GarcÃ­a, M. (2022).
Sistema de reconocimiento facial para el control de accesos mediante
Inteligencia Artificial. Revista de IniciaciÃ³n CientÃ­fica, 8(2), 1-10.
```

**URL:** https://www.redalyc.org/journal/6738/673874721016/html/

---

### 4.3 Reconocimiento de Gestos en SeÃ±ales BiomÃ©tricas

**[13] GÃ³mez-Vargas, D., et al. (2019).** *EvaluaciÃ³n de modelos para el reconocimiento de gestos en seÃ±ales biomÃ©tricas, para un usuario con movilidad reducida.* TecnoLÃ³gicas, 22(46), 115-135.

```
RESUMEN:
EvalÃºa diferentes modelos de ML (SVM, Random Forest, Redes Neuronales) para
reconocimiento de gestos en seÃ±ales biomÃ©tricas. Compara precisiÃ³n, velocidad
y requerimientos computacionales.

RELEVANCIA PARA VISION:
- EvaluaciÃ³n comparativa de modelos ML
- MÃ©tricas de rendimiento en tiempo real
- Trade-offs entre precisiÃ³n y velocidad
- SelecciÃ³n de modelos para aplicaciones especÃ­ficas

CITACIÃ“N APA:
GÃ³mez-Vargas, D., HernÃ¡ndez-Morales, S., & ArÃ©valo-Castiblanco, M. (2019).
EvaluaciÃ³n de modelos para el reconocimiento de gestos en seÃ±ales biomÃ©tricas,
para un usuario con movilidad reducida. TecnoLÃ³gicas, 22(46), 115-135.

DOI: 10.22430/22565337.1513
```

**URL:** https://revistas.itm.edu.co/index.php/tecnologicas/article/view/1513

---

### 4.4 TecnologÃ­as de Reconocimiento y ProtecciÃ³n de Datos

**[14] Silva-Monsalve, A., & RamÃ­rez-BenÃ­tez, E. (2023).** *TecnologÃ­as de reconocimiento facial en Colombia: AnÃ¡lisis comparativo en relaciÃ³n con la protecciÃ³n de datos.* Revista de Derecho, 59, 1-25.

```
RESUMEN:
Analiza las tecnologÃ­as de reconocimiento facial desde una perspectiva legal
y Ã©tica, enfocÃ¡ndose en la protecciÃ³n de datos personales. Revisa normativas
GDPR, CCPA y legislaciÃ³n colombiana.

RELEVANCIA PARA VISION:
- Consideraciones Ã©ticas y legales
- ProtecciÃ³n de datos personales (GDPR)
- Privacy-by-design
- Procesamiento local vs en servidor

CITACIÃ“N APA:
Silva-Monsalve, A., & RamÃ­rez-BenÃ­tez, E. (2023). TecnologÃ­as de
reconocimiento facial en Colombia: AnÃ¡lisis comparativo en relaciÃ³n con la
protecciÃ³n de datos. Revista de Derecho, 59, 1-25.

DOI: 10.4067/S0718-00122023000100003
```

**URL:** https://www.scielo.cl/scielo.php?pid=S0718-00122023000100003&script=sci_arttext

---

## 5. FRAMEWORKS Y LIBRERÃAS

### 5.1 face-api.js

**[15] MÃ¼hler, V. (2018).** *face-api.js: JavaScript API for Face Detection and Face Recognition in the Browser.* GitHub Repository.

```
DESCRIPCIÃ“N:
LibrerÃ­a JavaScript que implementa modelos de deep learning para detecciÃ³n
facial, landmarks, reconocimiento y expresiones. Construida sobre TensorFlow.js
y optimizada para navegadores modernos.

ESPECIFICACIONES TÃ‰CNICAS:
- VersiÃ³n: 0.22.2
- Licencia: MIT
- Modelos: TinyFaceDetector, FaceLandmark68Net, FaceRecognitionNet
- Backend: TensorFlow.js con WebGL
- TamaÃ±o: ~400KB (TinyFaceDetector) + ~350KB (Landmarks)

CITACIÃ“N TÃ‰CNICA:
V. MÃ¼hler, "face-api.js: JavaScript API for Face Detection and Face
Recognition in the Browser," GitHub, 2018. [Online]. Available:
https://github.com/justadudewhohacks/face-api.js
```

**URL:** https://github.com/justadudewhohacks/face-api.js
**DocumentaciÃ³n:** https://justadudewhohacks.github.io/face-api.js/docs/

---

### 5.2 TensorFlow.js

**[16] Smilkov, D., et al. (2019).** *TensorFlow.js: Machine Learning for the Web and Beyond.* Proceedings of Machine Learning and Systems (MLSys), 1, 309-321.

```
ABSTRACT:
TensorFlow.js es una librerÃ­a de cÃ³digo abierto para machine learning en
JavaScript, que permite entrenar y ejecutar modelos directamente en navegadores
y Node.js. Soporta mÃºltiples backends (WebGL, WASM, CPU).

ESPECIFICACIONES TÃ‰CNICAS:
- VersiÃ³n usada en VISION: 4.22.0
- Backends: WebGL (GPU), WebAssembly, CPU
- AceleraciÃ³n: 10-100x con WebGL
- Compatible: Chrome, Firefox, Safari, Edge

CITACIÃ“N IEEE:
D. Smilkov et al., "TensorFlow.js: Machine Learning for the Web and Beyond,"
in Proc. Machine Learning and Systems (MLSys), vol. 1, 2019, pp. 309-321.
```

**URL:** https://www.tensorflow.org/js
**Paper:** https://arxiv.org/abs/1901.05350

---

### 5.3 React

**[17] Facebook Open Source. (2013-2024).** *React: A JavaScript library for building user interfaces.* Meta Platforms, Inc.

```
DESCRIPCIÃ“N:
LibrerÃ­a JavaScript declarativa para construir interfaces de usuario mediante
componentes. Utiliza Virtual DOM para actualizaciones eficientes.

ESPECIFICACIONES TÃ‰CNICAS:
- VersiÃ³n usada en VISION: 18.2.0
- Paradigma: Componentes funcionales + Hooks
- Rendering: Virtual DOM
- Licencia: MIT

CITACIÃ“N TÃ‰CNICA:
Facebook Open Source, "React: A JavaScript library for building user
interfaces," Meta Platforms, Inc., 2013-2024. [Online]. Available:
https://react.dev/
```

**URL:** https://react.dev/

---

### 5.4 Material-UI (MUI)

**[18] MUI Team. (2014-2024).** *Material-UI: React components for faster and easier web development.* MIT License.

```
DESCRIPCIÃ“N:
Biblioteca de componentes React que implementa Material Design de Google.
Proporciona componentes pre-diseÃ±ados, accesibles y personalizables.

ESPECIFICACIONES TÃ‰CNICAS:
- VersiÃ³n usada en VISION: 5.15.10
- Componentes: 50+ componentes UI
- Theming: PersonalizaciÃ³n completa
- Accesibilidad: WCAG 2.1 AA

CITACIÃ“N TÃ‰CNICA:
MUI Team, "Material-UI: React components for faster and easier web
development," 2014-2024. [Online]. Available: https://mui.com/
```

**URL:** https://mui.com/

---

### 5.5 Socket.IO

**[19] Rauch, G. (2010-2024).** *Socket.IO: Realtime application framework.* MIT License.

```
DESCRIPCIÃ“N:
LibrerÃ­a que permite comunicaciÃ³n bidireccional en tiempo real entre clientes
web y servidores. Utiliza WebSockets con fallbacks automÃ¡ticos.

ESPECIFICACIONES TÃ‰CNICAS:
- VersiÃ³n usada en VISION: 4.8.1 (client), 4.7.4 (server)
- Protocolo: WebSocket (WSS en producciÃ³n)
- Fallbacks: Long-polling, HTTP streaming
- Latencia tÃ­pica: < 50ms

CITACIÃ“N TÃ‰CNICA:
G. Rauch, "Socket.IO: Realtime application framework," 2010-2024. [Online].
Available: https://socket.io/
```

**URL:** https://socket.io/

---

## 6. DATASETS DE ENTRENAMIENTO

### 6.1 VGGFace2

**[20] Cao, Q., Shen, L., Xie, W., Parkhi, O. M., & Zisserman, A. (2018).** *VGGFace2: A dataset for recognising faces across pose and age.* 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018), pp. 67-74.

```
ABSTRACT:
Dataset a gran escala para reconocimiento facial con 3.31 millones de imÃ¡genes
de 9,131 sujetos. Incluye variaciones significativas en pose, edad, iluminaciÃ³n
y oclusiones. Usado para entrenar FaceRecognitionNet.

ESPECIFICACIONES:
- ImÃ¡genes: 3,310,000
- Identidades: 9,131
- Promedio por identidad: 362.6 imÃ¡genes
- ResoluciÃ³n: Variable (mÃ­nimo 224x224)
- Licencia: Uso acadÃ©mico

CITACIÃ“N IEEE:
Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, "VGGFace2: A
dataset for recognising faces across pose and age," in Proc. 13th IEEE Int.
Conf. Automatic Face & Gesture Recognition (FG), 2018, pp. 67-74.

DOI: 10.1109/FG.2018.00020
```

**URL:** https://github.com/ox-vgg/vgg_face2

---

### 6.2 WIDER FACE

**[21] Yang, S., Luo, P., Loy, C. C., & Tang, X. (2016).** *WIDER FACE: A Face Detection Benchmark.* IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5525-5533.

```
ABSTRACT:
Dataset para detecciÃ³n facial con 32,203 imÃ¡genes y 393,703 rostros anotados
con alta variabilidad en escala, pose y oclusiÃ³n. Categoriza las imÃ¡genes en
tres niveles de dificultad: fÃ¡cil, medio y difÃ­cil.

ESPECIFICACIONES:
- ImÃ¡genes: 32,203
- Rostros anotados: 393,703
- Eventos: 61 categorÃ­as
- Niveles: FÃ¡cil, Medio, DifÃ­cil
- Usado para: Entrenar TinyFaceDetector

CITACIÃ“N IEEE:
S. Yang, P. Luo, C. C. Loy, and X. Tang, "WIDER FACE: A Face Detection
Benchmark," in Proc. IEEE Conf. Computer Vision and Pattern Recognition
(CVPR), 2016, pp. 5525-5533.

DOI: 10.1109/CVPR.2016.596
```

**URL:** http://shuoyang1213.me/WIDERFACE/

---

## 7. NORMATIVAS Y ESTÃNDARES

### 7.1 GDPR - ProtecciÃ³n de Datos

**[22] Reglamento (UE) 2016/679** del Parlamento Europeo y del Consejo, de 27 de abril de 2016, relativo a la protecciÃ³n de las personas fÃ­sicas en lo que respecta al tratamiento de datos personales y a la libre circulaciÃ³n de estos datos.

```
RELEVANCIA PARA VISION:
- Procesamiento local de datos biomÃ©tricos (sin servidor)
- MinimizaciÃ³n de datos
- Privacy by design
- Derecho al olvido (soft deletes)
- Consentimiento explÃ­cito para uso de cÃ¡mara

ARTÃCULOS APLICABLES:
- Art. 4(14): Datos biomÃ©tricos
- Art. 9: Tratamiento de categorÃ­as especiales de datos
- Art. 25: ProtecciÃ³n de datos desde el diseÃ±o
- Art. 32: Seguridad del tratamiento

CITACIÃ“N:
Reglamento (UE) 2016/679 del Parlamento Europeo y del Consejo, de 27 de
abril de 2016 (GDPR). Diario Oficial de la UniÃ³n Europea, L 119/1.
```

**URL:** https://eur-lex.europa.eu/eli/reg/2016/679/oj

---

### 7.2 ISO/IEC 30107 - Biometric Presentation Attack Detection

**[23] ISO/IEC 30107-1:2016.** Information technology â€” Biometric presentation attack detection â€” Part 1: Framework.

```
DESCRIPCIÃ“N:
EstÃ¡ndar internacional para detecciÃ³n de ataques de presentaciÃ³n en sistemas
biomÃ©tricos. Define terminologÃ­a, conceptos y mÃ©tricas para evaluar la
robustez contra spoofing.

RELEVANCIA PARA VISION:
- DetecciÃ³n de ataques (fotos, videos, mÃ¡scaras)
- MÃ©tricas de evaluaciÃ³n (APCER, BPCER)
- Liveness detection (no implementado actualmente)
- Consideraciones de seguridad

CITACIÃ“N:
ISO/IEC 30107-1:2016, Information technology â€” Biometric presentation
attack detection â€” Part 1: Framework. International Organization for
Standardization, 2016.
```

**URL:** https://www.iso.org/standard/53227.html

---

### 7.3 WebGL 2.0 Specification

**[24] Khronos Group. (2017).** *WebGL 2.0 Specification.* Editor's Draft.

```
DESCRIPCIÃ“N:
EspecificaciÃ³n de la API WebGL 2.0 para renderizado 3D/2D en navegadores web
con aceleraciÃ³n por hardware. Basada en OpenGL ES 3.0.

RELEVANCIA PARA VISION:
- Backend de TensorFlow.js para aceleraciÃ³n GPU
- Operaciones tensoriales aceleradas
- Shaders para cÃ¡lculos paralelos
- 10-100x mÃ¡s rÃ¡pido que CPU

CITACIÃ“N TÃ‰CNICA:
Khronos Group, "WebGL 2.0 Specification," Editor's Draft, 2017. [Online].
Available: https://www.khronos.org/registry/webgl/specs/latest/2.0/
```

**URL:** https://www.khronos.org/webgl/

---

## 8. CITAS EN EL PROYECTO

### 8.1 Algoritmo EAR (Eye Aspect Ratio)

```typescript
// drowsinessDetection.service.ts
// Basado en: SoukupovÃ¡ & ÄŒech (2016) [1]

/**
 * Calcula el Eye Aspect Ratio (EAR) para detectar ojos cerrados.
 * 
 * ImplementaciÃ³n del mÃ©todo propuesto por SoukupovÃ¡ & ÄŒech (2016) en
 * "Real-Time Eye Blink Detection using Facial Landmarks".
 * 
 * FÃ³rmula: EAR = (||p2-p6|| + ||p3-p5||) / (2 * ||p1-p4||)
 * 
 * @param eye Array de 6 puntos del ojo (landmarks 36-41 o 42-47)
 * @returns Valor EAR (tÃ­picamente 0.15-0.40)
 * 
 * @reference SoukupovÃ¡, T., & ÄŒech, J. (2016). Real-Time Eye Blink
 * Detection using Facial Landmarks. 21st Computer Vision Winter Workshop.
 */
private calculateEAR(eye: faceapi.Point[]): number {
  // Distancias verticales
  const A = this.euclideanDistance(eye[1], eye[5]);  // |p2 - p6|
  const B = this.euclideanDistance(eye[2], eye[4]);  // |p3 - p5|
  
  // Distancia horizontal
  const C = this.euclideanDistance(eye[0], eye[3]);  // |p1 - p4|
  
  // Calcular EAR segÃºn SoukupovÃ¡ & ÄŒech (2016)
  const ear = (A + B) / (2.0 * C);
  
  return ear;
}
```

---

### 8.2 Umbrales de DetecciÃ³n

```typescript
// drowsinessDetection.service.ts
// Umbrales calibrados basados en literatura cientÃ­fica [1, 9]

private readonly EYE_AR_THRESH = 0.29;  // Ojos cerrados si EAR < 0.29
// SoukupovÃ¡ & ÄŒech (2016) sugieren 0.3, ajustado a 0.29 para VISION

private readonly YAWN_THRESH = 0.45;    // Bostezo si MAR > 0.45
// Adaptado de EAR para la regiÃ³n de la boca [9]

private readonly EYE_AR_CONSEC_FRAMES = 1;  // Frames consecutivos
private readonly YAWN_CONSEC_FRAMES = 1;    // Reducido para sensibilidad
```

---

### 8.3 Arquitectura de Modelos

```typescript
// drowsinessDetection.service.ts
// Modelos basados en investigaciÃ³n acadÃ©mica [2, 3, 4, 5]

/**
 * Carga los modelos de face-api.js pre-entrenados:
 * 
 * 1. TinyFaceDetector: Basado en MobileNets [5]
 *    - Arquitectura: Depthwise Separable CNN
 *    - ParÃ¡metros: ~400,000
 *    - Dataset: WIDER FACE [21]
 * 
 * 2. FaceLandmark68Net: Basado en iBUG 300-W [4]
 *    - Arquitectura: CNN para regresiÃ³n de puntos
 *    - Landmarks: 68 puntos faciales
 *    - Dataset: 300 Faces In-The-Wild [4]
 * 
 * 3. FaceRecognitionNet: Basado en ResNet-34 [2] y FaceNet [3]
 *    - Arquitectura: ResNet-34 (34 capas)
 *    - Output: 128D face embeddings
 *    - Dataset: VGGFace2 [20]
 */
async loadModels(): Promise<void> {
  const MODEL_URL = '/models';
  
  await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
  await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
  await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
  
  this.modelsLoaded = true;
}
```

---

### 8.4 Privacy by Design

```typescript
// api.ts & socket.service.ts
// ImplementaciÃ³n de Privacy by Design segÃºn GDPR [22]

/**
 * VISION implementa procesamiento local de datos biomÃ©tricos
 * conforme al ArtÃ­culo 9 del GDPR [22].
 * 
 * Principios aplicados:
 * 1. MinimizaciÃ³n de datos: Solo se capturan frames de video necesarios
 * 2. Procesamiento local: face-api.js ejecuta en navegador (sin servidor)
 * 3. No almacenamiento: Frames de video NO se guardan en servidor
 * 4. AnonimizaciÃ³n: Solo mÃ©tricas numÃ©ricas (EAR, MAR) se transmiten
 * 5. Consentimiento: Usuario debe autorizar acceso a cÃ¡mara
 * 
 * @reference Reglamento (UE) 2016/679 (GDPR), Art. 9, 25, 32
 */
```

---

## ğŸ“Š RESUMEN DE REFERENCIAS POR CATEGORÃA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DISTRIBUCIÃ“N DE REFERENCIAS                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Papers CientÃ­ficos Fundamentales:      5 referencias  â”‚
â”‚  Estudios de DetecciÃ³n de Somnolencia:  5 referencias  â”‚
â”‚  Reconocimiento Facial e IA:            4 referencias  â”‚
â”‚  Frameworks y LibrerÃ­as:                5 referencias  â”‚
â”‚  Datasets de Entrenamiento:             2 referencias  â”‚
â”‚  Normativas y EstÃ¡ndares:               3 referencias  â”‚
â”‚                                        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  TOTAL:                                24 referencias  â”‚
â”‚                                                         â”‚
â”‚  Por tipo:                                              â”‚
â”‚  â€¢ Papers IEEE/CVPR:         8 (33%)                   â”‚
â”‚  â€¢ ArtÃ­culos de revista:     7 (29%)                   â”‚
â”‚  â€¢ DocumentaciÃ³n tÃ©cnica:    5 (21%)                   â”‚
â”‚  â€¢ Normativas:               3 (13%)                   â”‚
â”‚  â€¢ Datasets:                 2 (8%)                    â”‚
â”‚                                                         â”‚
â”‚  Por idioma:                                            â”‚
â”‚  â€¢ InglÃ©s:                  14 (58%)                   â”‚
â”‚  â€¢ EspaÃ±ol:                 10 (42%)                   â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ CÃ“MO CITAR ESTE PROYECTO

### Formato APA 7Âª EdiciÃ³n

```
Montufar Merma, R. D. (2025). VISION: Sistema de DetecciÃ³n de Somnolencia
en Conductores mediante VisiÃ³n por Computadora y Aprendizaje Profundo
[Software]. https://github.com/rogeero/vision
```

### Formato IEEE

```
R. D. Montufar Merma, "VISION: Sistema de DetecciÃ³n de Somnolencia en
Conductores mediante VisiÃ³n por Computadora y Aprendizaje Profundo," 2025.
[Software]. Available: https://github.com/rogeero/vision
```

### BibTeX

```bibtex
@software{montufar2025vision,
  author = {Montufar Merma, Rogeero Daniel},
  title = {VISION: Sistema de DetecciÃ³n de Somnolencia en Conductores
           mediante VisiÃ³n por Computadora y Aprendizaje Profundo},
  year = {2025},
  url = {https://github.com/rogeero/vision},
  note = {Sistema web en tiempo real utilizando face-api.js, TensorFlow.js,
          React y Socket.IO}
}
```

---

## ğŸ”— ENLACES ÃšTILES

### Repositorios y DocumentaciÃ³n

- **Proyecto VISION:** [Repositorio GitHub]
- **face-api.js:** https://github.com/justadudewhohacks/face-api.js
- **TensorFlow.js:** https://www.tensorflow.org/js
- **React:** https://react.dev/
- **Socket.IO:** https://socket.io/

### Papers y Datasets

- **ArXiv (Papers ML/CV):** https://arxiv.org/
- **IEEE Xplore:** https://ieeexplore.ieee.org/
- **Google Scholar:** https://scholar.google.com/
- **Papers With Code:** https://paperswithcode.com/

### Recursos Educativos

- **Curso TensorFlow.js:** https://www.tensorflow.org/js/tutorials
- **Computer Vision Course:** https://www.coursera.org/learn/computer-vision
- **Deep Learning Specialization:** https://www.coursera.org/specializations/deep-learning

---

## ğŸ“„ LICENCIA DE ESTE DOCUMENTO

Este documento de referencias bibliogrÃ¡ficas estÃ¡ bajo licencia **Creative Commons Attribution 4.0 International (CC BY 4.0)**.

Usted es libre de:
- **Compartir** â€” copiar y redistribuir el material en cualquier medio o formato
- **Adaptar** â€” remezclar, transformar y construir a partir del material para cualquier propÃ³sito

Bajo los siguientes tÃ©rminos:
- **AtribuciÃ³n** â€” Debe dar crÃ©dito apropiado, proporcionar un enlace a la licencia e indicar si se han realizado cambios.

---

**Proyecto:** VISION - Sistema de DetecciÃ³n de Somnolencia
**VersiÃ³n:** 1.0.0
**Autor:** Rogeero Daniel Montufar Merma
**Fecha:** Octubre 2025
**Ãšltima actualizaciÃ³n:** 27 de Octubre de 2025

